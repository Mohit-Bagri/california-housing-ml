# ğŸ¡ California Housing Price Prediction (Regression)

This project predicts median house prices in California districts using the **California Housing dataset** from scikit-learn.

The goal of this lab is to practice:

- Regression modeling  
- Feature scaling  
- Hyperparameter tuning  
- Comparing linear vs tree-based models  

---

## ğŸ“‚ Project Structure

```
california-housing-ml/
â”‚
â”œâ”€â”€ main.py               # End-to-end ML pipeline
â”œâ”€â”€ requirements.txt      # Dependencies
â””â”€â”€ README.md
```

---

## ğŸ“Š Dataset

We use the built-in dataset:

```
from sklearn.datasets import fetch_california_housing
```

**Features include:**

- Median income  
- House age  
- Average rooms  
- Population  
- Latitude, longitude  
- â€¦and more  

**Target variable:**

```
MedHouseVal  â†’ median house value (in $100,000 units)
```

---

## ğŸ¤– Models Used

### **1. Ridge Regression (Linear Model)**  
- Uses StandardScaler  
- Hyperparameter tuning with GridSearchCV  
- Evaluated using **RMSE, MAE, RÂ²**

---

### **2. Random Forest Regressor (Tree Model)**  
- Non-linear model  
- No scaling required  
- Compared against Ridge  

---

## â–¶ï¸ How to Run

Install dependencies:

```
pip install -r requirements.txt
```

Run the project:

```
python main.py
```

---

## ğŸ“ˆ Results (Example Output)

```
=== Ridge Regression Results ===
RMSE: 0.74
MAE : 0.53
RÂ²  : 0.57

=== Random Forest Regression Results ===
RMSE: 0.50
MAE : 0.32
RÂ²  : 0.80
```

Random Forest generally performs better because it captures **non-linear patterns** in the housing data.

---

## âœ… Summary

- Ridge (linear) learns a smooth relationship  
- Random Forest captures complex, non-linear interactions  
- Feature scaling is required only for linear models  
- Tree models work well out-of-the-box  

---

